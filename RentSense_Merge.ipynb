{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLSZ7CbH608l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "weights = pd.Series(\n",
        "    index=[\"Commute Convenience\", \"Safety\", \"Noise\", \"Amenity Convenience\", \"Green Space Accessibility\", \"Job Opportunities\", \"Education Access\", \"Political Leaning\"],\n",
        "    data=[1, 1, 1, 1, 1, 1, 1, 1]\n",
        ")\n",
        "\n",
        "values = pd.DataFrame(\n",
        "    index = [\"Hudson Yards\", \"Morningside Heights\", \"Harlem\"],\n",
        "    data = {\n",
        "        \"Commute Convenience\": [0.39, 0.21, 0.19],\n",
        "        \"Safety\": [0.90, 0.57, 0.62],\n",
        "        \"Noise\": [0.5, 0.5, 0.5],\n",
        "        \"Amenity Convenience\": [0.39, 0.11, 0.08],\n",
        "        \"Green Space Accessibility\": [0.69, 0.76, 0.74],\n",
        "        \"Job Opportunities\": [0.91, 0.27, 0.28],\n",
        "        \"Education Access\": [0.11, 0.1, 0.1],\n",
        "        \"Political Leaning\": [0.35, 0.45, 0.55]\n",
        "    }\n",
        ")\n",
        "\n",
        "costs = pd.Series(\n",
        "    index = [\"Hudson Yards\", \"Morningside Heights\", \"Harlem\"],\n",
        "    data = [18000, 16000, 10000]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0XxVyVs7NBd"
      },
      "outputs": [],
      "source": [
        "# This is the overall quality of life rating, finding the \"best\" possible location to live in, based on the user's preferences\n",
        "# In this mode, cost is a factor that is taken into consideration in the calculation. (To disable, set its weight to 0.)\n",
        "# The function returns a value between 0 and 1, where 0 indicates minimal fit, and 1 indicates maximum fit.\n",
        "# We can think of this as answering: \"Where would I be most happy?\"\n",
        "\n",
        "def calculate_fit_index(location: str):\n",
        "    qol_value = (weights * values.loc[location]).sum()\n",
        "    weights_sum = weights.sum()\n",
        "    return qol_value / weights_sum\n",
        "\n",
        "\n",
        "# This is the best value rating, finding places that give you the most \"bang for your buck\".\n",
        "# The QoL value is calculated WITHOUT taking cost into consideration.\n",
        "# This QoL value is then divided by the cost value; hence, \"bang for your buck\". Or in other words: QoL per Dollar.\n",
        "# We can think of this as answering: \"Where is the best deal?\"\n",
        "\n",
        "def calculate_return_on_investment(location: str):\n",
        "    qol_value = (weights.drop(labels=\"Cost\") * values.drop(columns=\"Cost\").loc[location]).sum()\n",
        "    cost = costs[location]\n",
        "\n",
        "    # Note that we take the natural log of the cost of living, because the significance of cost is not linear.\n",
        "    # For example, consider:\n",
        "        # Neighborhood A: QoL = 0.5, Cost = 2 (Very Cheap). Ratio = 0.25\n",
        "        # Neighborhood B: QoL = 1.0 (Perfect!), Cost = 5 (Average). Ratio = 0.20\n",
        "    # If we use a linear scale for the cost, Neighborhood A has a better cost ratio.\n",
        "    # Any neighborhood with a low cost value like 1 or 2, regardless of their actual fit, would get a very good result. We don't want that.\n",
        "    return qol_value / np.log(cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OXf9Rhe7Pp_"
      },
      "outputs": [],
      "source": [
        "for location in values.index.tolist():\n",
        "    values.loc[location, \"Fit Index\"] = calculate_fit_index(location)\n",
        "\n",
        "for location in values.index.tolist():\n",
        "    values.loc[location, \"ROI\"] = calculate_return_on_investment(location)\n",
        "\n",
        "values.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoZPvwBfQ_g9",
        "outputId": "fa5e864e-2c20-4092-cbca-df11be62b4c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "   üè† RENTSENSE - Neighborhood Recommendation Engine\n",
            "============================================================\n",
            "\n",
            "Are you new to NYC or already living here?\n",
            "\n",
            "  1) I'm new to NYC (Discovery Mode)\n",
            "  2) I already live here (Migration Mode)\n",
            "\n",
            "Your choice (1 or 2): 2\n",
            "\n",
            "============================================================\n",
            "   RENTSENSE - Migration Mode\n",
            "   Already in NYC? Let's find somewhere better.\n",
            "============================================================\n",
            "\n",
            "What's your current ZIP code? 11355\n",
            "\n",
            "üìç Got it ‚Äî 11355\n",
            "\n",
            "Tell me: What do you love AND what would you change\n",
            "about your current neighborhood?\n",
            "\n",
            "You: I like the access to amenities like supermarkets and parks, but I think the nearby education opportunities are not very good. I'd prefer a neighborhood with nearby schools\n",
            "\n",
            "üîç Understanding your experience...\n",
            "\n",
            "‚úì I heard you:\n",
            "   ‚Ä¢ Amenity Convenience: I like the access to amenities like supermarkets\n",
            "   ‚Ä¢ Green Space Accessibility: I like the access to amenities like supermarkets and parks\n",
            "   ‚Ä¢ Education Access: I think the nearby education opportunities are not very good. I'd prefer a neighborhood with nearby schools\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Question 1\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "You mentioned prioritizing neighborhoods with good nearby schools, which often goes hand-in-hand with feeling secure. How high a priority is safety for you in your ideal neighborhood?\n",
            "\n",
            "  A) It's a top priority; feeling very safe and secure is essential.\n",
            "  B) It's important, but I can be a bit flexible if other features are excellent.\n",
            "  C) While nice to have, it's less of a primary concern compared to amenities and school access.\n",
            "\n",
            "  S) Skip\n",
            "  X) Show results now\n",
            "\n",
            "Your choice: A\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Question 2\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "Given your emphasis on finding a neighborhood with good schools, nearby amenities, and top-tier safety, let's talk about your daily travels. How much does commute convenience factor into your ideal neighborhood for work or other regular activities?\n",
            "\n",
            "  A) Extremely important ‚Äì I need a very quick and easy commute for work and errands, ideally walkable or with excellent public transport.\n",
            "  B) Moderately important ‚Äì A reasonable commute is fine, but I wouldn't want it to be overly long or difficult.\n",
            "  C) Less of a concern ‚Äì I'm willing to have a longer commute if the neighborhood checks all the other boxes like safety and schools.\n",
            "\n",
            "  S) Skip\n",
            "  X) Show results now\n",
            "\n",
            "Your choice: C\n",
            "\n",
            "============================================================\n",
            "YOUR PREFERENCE WEIGHTS (sum to 8)\n",
            "============================================================\n",
            "\n",
            "  Safety                       1.87  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë\n",
            "  Amenity Convenience          1.40  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë\n",
            "  Green Space Accessibility    1.40  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë\n",
            "  Education Access             1.40  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë\n",
            "  Noise                        0.56  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
            "  Job Opportunities            0.56  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
            "  Political Leaning            0.56  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
            "  Commute Convenience          0.25  ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Total: 8.00\n",
            "Questions asked: 2\n",
            "Dimensions covered: 5/8\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "üìã Summary:\n",
            "   Your top priorities: Safety, Amenity Convenience, Green Space Accessibility\n",
            "\n",
            "‚úì Done! Next step: Use these weights to score neighborhoods.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "RENTSENSE - Question Engine v2\n",
        "Hackathon: NexHacks 2026\n",
        "\n",
        "Gemini-powered contextual question generation.\n",
        "Questions feel personal, not like a survey.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from google import genai\n",
        "\n",
        "# ============================================================\n",
        "# CONFIG\n",
        "# ============================================================\n",
        "\n",
        "API_KEY = \"API_KEY\"  # Replace with your key\n",
        "\n",
        "DIMENSIONS = [\n",
        "    \"Commute Convenience\",\n",
        "    \"Safety\",\n",
        "    \"Noise\",\n",
        "    \"Amenity Convenience\",\n",
        "    \"Green Space Accessibility\",\n",
        "    \"Job Opportunities\",\n",
        "    \"Education Access\",\n",
        "    \"Political Leaning\"\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# GEMINI CLIENT\n",
        "# ============================================================\n",
        "\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "def call_gemini(prompt):\n",
        "    \"\"\"Call Gemini API and return response text.\"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model='gemini-2.5-flash',\n",
        "        contents=prompt\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# QUESTION ENGINE v2\n",
        "# ============================================================\n",
        "\n",
        "class QuestionEngineV2:\n",
        "\n",
        "    def __init__(self, mode=\"discovery\"):\n",
        "        self.mode = mode\n",
        "        self.conversation_history = []\n",
        "\n",
        "        # Initialize weights (8 dimensions, each starts at 1.0, sum = 8)\n",
        "        self.weights = {dim: 1.0 for dim in DIMENSIONS}\n",
        "\n",
        "        # Track state\n",
        "        self.questions_asked = 0\n",
        "        self.dimensions_covered = set()\n",
        "        self.user_context = \"\"\n",
        "        self.zip_code = None  # For migration mode\n",
        "\n",
        "    def analyze_input(self, user_input):\n",
        "        \"\"\"Use Gemini to analyze what's CLEAR, AMBIGUOUS, and MISSING.\"\"\"\n",
        "\n",
        "        self.user_context = user_input\n",
        "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are analyzing a user's housing preference input to understand what they care about.\n",
        "\n",
        "USER INPUT: \"{user_input}\"\n",
        "\n",
        "MODE: {self.mode} ({\"new to the city\" if self.mode == \"discovery\" else \"already lives here, moving within city\"})\n",
        "\n",
        "DIMENSIONS TO EVALUATE:\n",
        "{json.dumps(DIMENSIONS, indent=2)}\n",
        "\n",
        "Analyze the input and categorize each dimension:\n",
        "\n",
        "1. CLEAR - User explicitly mentioned this, we know their preference\n",
        "2. AMBIGUOUS - User hinted at this but needs clarification\n",
        "3. MISSING - User didn't mention this at all\n",
        "\n",
        "Also extract any specific details (job location, budget mentioned, specific concerns, etc.)\n",
        "\n",
        "Respond in this exact JSON format:\n",
        "{{\n",
        "    \"clear\": {{\n",
        "        \"dimension_name\": {{\"preference\": \"high/medium/low\", \"evidence\": \"what they said\", \"weight_delta\": 1.5}},\n",
        "        ...\n",
        "    }},\n",
        "    \"ambiguous\": {{\n",
        "        \"dimension_name\": {{\"hint\": \"what they hinted at\", \"needs_clarification\": \"what to ask\"}},\n",
        "        ...\n",
        "    }},\n",
        "    \"missing\": [\"dimension1\", \"dimension2\", ...],\n",
        "    \"extracted_details\": {{\n",
        "        \"job_location\": \"if mentioned\",\n",
        "        \"budget\": \"if mentioned\",\n",
        "        \"specific_concerns\": [\"list of concerns\"],\n",
        "        \"other\": \"any other relevant details\"\n",
        "    }}\n",
        "}}\n",
        "\n",
        "Respond with ONLY the JSON, no other text.\n",
        "\"\"\"\n",
        "\n",
        "        response = call_gemini(prompt)\n",
        "\n",
        "        # Parse JSON (handle potential formatting issues)\n",
        "        try:\n",
        "            # Clean up response if needed\n",
        "            response = response.strip()\n",
        "            if response.startswith(\"```json\"):\n",
        "                response = response[7:]\n",
        "            if response.startswith(\"```\"):\n",
        "                response = response[3:]\n",
        "            if response.endswith(\"```\"):\n",
        "                response = response[:-3]\n",
        "\n",
        "            analysis = json.loads(response.strip())\n",
        "\n",
        "            # Apply weight deltas for CLEAR dimensions\n",
        "            if \"clear\" in analysis:\n",
        "                for dim, info in analysis[\"clear\"].items():\n",
        "                    if dim in self.weights and \"weight_delta\" in info:\n",
        "                        self.weights[dim] += info[\"weight_delta\"]\n",
        "                        self.dimensions_covered.add(dim)\n",
        "\n",
        "            # Normalize after applying deltas\n",
        "            self._normalize_weights()\n",
        "\n",
        "            return analysis\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Warning: Could not parse analysis JSON: {e}\")\n",
        "            print(f\"Raw response: {response}\")\n",
        "            return {\"clear\": {}, \"ambiguous\": {}, \"missing\": DIMENSIONS, \"extracted_details\": {}}\n",
        "\n",
        "    def generate_question(self, analysis):\n",
        "        \"\"\"Use Gemini to generate a contextual question based on analysis.\"\"\"\n",
        "\n",
        "        # Determine what to focus on\n",
        "        if analysis.get(\"ambiguous\"):\n",
        "            focus = \"ambiguous\"\n",
        "            target = list(analysis[\"ambiguous\"].keys())[0]\n",
        "            context = analysis[\"ambiguous\"][target]\n",
        "        elif analysis.get(\"missing\"):\n",
        "            focus = \"missing\"\n",
        "            # Pick most important missing dimension\n",
        "            priority_order = [\"Safety\", \"Commute Convenience\", \"Noise\", \"Amenity Convenience\",\n",
        "                           \"Green Space Accessibility\", \"Education Access\", \"Job Opportunities\", \"Political Leaning\"]\n",
        "            target = None\n",
        "            for dim in priority_order:\n",
        "                if dim in analysis[\"missing\"] and dim not in self.dimensions_covered:\n",
        "                    target = dim\n",
        "                    break\n",
        "            if not target:\n",
        "                return None\n",
        "            context = {}\n",
        "        else:\n",
        "            return None  # Nothing to ask\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a friendly housing consultant helping someone find their perfect neighborhood.\n",
        "\n",
        "USER'S ORIGINAL INPUT: \"{self.user_context}\"\n",
        "\n",
        "CONVERSATION SO FAR:\n",
        "{json.dumps(self.conversation_history, indent=2)}\n",
        "\n",
        "YOU NEED TO ASK ABOUT: {target}\n",
        "REASON: {\"User hinted at this but needs clarification\" if focus == \"ambiguous\" else \"User hasn't mentioned this yet\"}\n",
        "{f\"HINT FROM USER: {context.get('hint', '')}\" if focus == \"ambiguous\" else \"\"}\n",
        "\n",
        "Generate a contextual, conversational question that:\n",
        "1. References something specific from their input (makes it feel personal)\n",
        "2. Asks about {target} in a natural way\n",
        "3. Provides clear options with different preference levels\n",
        "\n",
        "Choose the best FORMAT:\n",
        "- MCQ_SINGLE: When there are distinct preference levels (use most often)\n",
        "- MCQ_MULTI: When user might value multiple things (good for amenities, what they love/hate)\n",
        "- YES_NO: For simple binary questions (do you have kids, do you have a car)\n",
        "\n",
        "Respond in this exact JSON format:\n",
        "{{\n",
        "    \"format\": \"MCQ_SINGLE\" or \"MCQ_MULTI\" or \"YES_NO\",\n",
        "    \"dimension\": \"{target}\",\n",
        "    \"question\": \"Your contextual question here\",\n",
        "    \"options\": [\n",
        "        {{\"id\": \"A\", \"label\": \"Option text\", \"weight_delta\": 1.5}},\n",
        "        {{\"id\": \"B\", \"label\": \"Option text\", \"weight_delta\": 0.5}},\n",
        "        {{\"id\": \"C\", \"label\": \"Option text\", \"weight_delta\": -0.3}}\n",
        "    ]\n",
        "}}\n",
        "\n",
        "RULES FOR weight_delta:\n",
        "- High importance to user ‚Üí +1.0 to +1.5\n",
        "- Medium importance ‚Üí +0.3 to +0.5\n",
        "- Low importance / don't care ‚Üí -0.3 to -0.5\n",
        "- For MCQ_MULTI, use smaller deltas (+0.3 to +0.5 each) since they can select multiple\n",
        "\n",
        "Make the question feel PERSONAL and CONVERSATIONAL, not like a survey.\n",
        "Respond with ONLY the JSON, no other text.\n",
        "\"\"\"\n",
        "\n",
        "        response = call_gemini(prompt)\n",
        "\n",
        "        try:\n",
        "            # Clean up response\n",
        "            response = response.strip()\n",
        "            if response.startswith(\"```json\"):\n",
        "                response = response[7:]\n",
        "            if response.startswith(\"```\"):\n",
        "                response = response[3:]\n",
        "            if response.endswith(\"```\"):\n",
        "                response = response[:-3]\n",
        "\n",
        "            question_data = json.loads(response.strip())\n",
        "            question_data[\"target_dimension\"] = target\n",
        "            return question_data\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Warning: Could not parse question JSON: {e}\")\n",
        "            print(f\"Raw response: {response}\")\n",
        "            return None\n",
        "\n",
        "    def process_answer(self, question_data, selected_ids):\n",
        "        \"\"\"Process user's answer and update weights.\"\"\"\n",
        "\n",
        "        self.questions_asked += 1\n",
        "\n",
        "        # Find selected options and apply weight deltas\n",
        "        for option in question_data[\"options\"]:\n",
        "            if option[\"id\"] in selected_ids:\n",
        "                dim = question_data.get(\"dimension\") or question_data.get(\"target_dimension\")\n",
        "                if dim and dim in self.weights:\n",
        "                    self.weights[dim] += option.get(\"weight_delta\", 0)\n",
        "                    self.dimensions_covered.add(dim)\n",
        "\n",
        "        # Add to conversation history\n",
        "        selected_labels = [opt[\"label\"] for opt in question_data[\"options\"] if opt[\"id\"] in selected_ids]\n",
        "        self.conversation_history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": question_data[\"question\"]\n",
        "        })\n",
        "        self.conversation_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \", \".join(selected_labels)\n",
        "        })\n",
        "\n",
        "        # Normalize weights to sum to 8\n",
        "        self._normalize_weights()\n",
        "\n",
        "    def _normalize_weights(self):\n",
        "        \"\"\"Normalize weights to sum to 8.\"\"\"\n",
        "        total = sum(self.weights.values())\n",
        "        if total > 0:\n",
        "            self.weights = {k: (v / total) * 8 for k, v in self.weights.items()}\n",
        "\n",
        "    def get_weights(self):\n",
        "        \"\"\"Return current weights, sorted by value (always normalized to sum to 8).\"\"\"\n",
        "        self._normalize_weights()  # Ensure normalized before returning\n",
        "        return dict(sorted(self.weights.items(), key=lambda x: -x[1]))\n",
        "\n",
        "    def should_continue(self, max_questions=5):\n",
        "        \"\"\"Check if we should ask more questions.\"\"\"\n",
        "        if self.questions_asked >= max_questions:\n",
        "            return False\n",
        "        if len(self.dimensions_covered) >= len(DIMENSIONS) - 2:  # Most covered\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN RUNNER\n",
        "# ============================================================\n",
        "\n",
        "def run_discovery_mode():\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"   RENTSENSE - Discovery Mode\")\n",
        "    print(\"   New to NYC? Let's find your perfect neighborhood.\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    engine = QuestionEngineV2(mode=\"discovery\")\n",
        "\n",
        "    # Get initial input\n",
        "    print(\"\\nTell me about yourself and what you're looking for.\")\n",
        "    print(\"(Job location, concerns, lifestyle, budget, anything relevant)\\n\")\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Analyze input\n",
        "    print(\"\\nüîç Understanding your needs...\")\n",
        "    analysis = engine.analyze_input(user_input)\n",
        "\n",
        "    # Show what we understood\n",
        "    if analysis.get(\"clear\"):\n",
        "        print(\"\\n‚úì Got it! I understood:\")\n",
        "        for dim, info in analysis[\"clear\"].items():\n",
        "            print(f\"   ‚Ä¢ {dim}: {info.get('evidence', 'mentioned')}\")\n",
        "\n",
        "    # Question loop\n",
        "    max_questions = 4  # Discovery gets more questions\n",
        "\n",
        "    while engine.should_continue(max_questions):\n",
        "        # Generate contextual question\n",
        "        question_data = engine.generate_question(analysis)\n",
        "\n",
        "        if not question_data:\n",
        "            break\n",
        "\n",
        "        # Display question\n",
        "        print(f\"\\n{'‚îÄ' * 50}\")\n",
        "        print(f\"Question {engine.questions_asked + 1}\")\n",
        "        print(f\"{'‚îÄ' * 50}\")\n",
        "        print(f\"\\n{question_data['question']}\\n\")\n",
        "\n",
        "        for opt in question_data[\"options\"]:\n",
        "            print(f\"  {opt['id']}) {opt['label']}\")\n",
        "\n",
        "        if question_data[\"format\"] == \"MCQ_MULTI\":\n",
        "            print(f\"\\n  (Select multiple, comma-separated: A,C)\")\n",
        "\n",
        "        print(f\"\\n  S) Skip\")\n",
        "        print(f\"  X) Show results now\")\n",
        "\n",
        "        # Get answer\n",
        "        answer = input(\"\\nYour choice: \").strip().upper()\n",
        "\n",
        "        if answer == \"X\":\n",
        "            break\n",
        "        elif answer == \"S\":\n",
        "            engine.questions_asked += 1\n",
        "            # Update analysis to try next dimension\n",
        "            if question_data.get(\"target_dimension\") in analysis.get(\"missing\", []):\n",
        "                analysis[\"missing\"].remove(question_data[\"target_dimension\"])\n",
        "        else:\n",
        "            selected = [a.strip() for a in answer.split(\",\")]\n",
        "            valid_ids = [opt[\"id\"] for opt in question_data[\"options\"]]\n",
        "            selected = [s for s in selected if s in valid_ids]\n",
        "\n",
        "            if selected:\n",
        "                engine.process_answer(question_data, selected)\n",
        "                # Update analysis\n",
        "                if question_data.get(\"target_dimension\") in analysis.get(\"missing\", []):\n",
        "                    analysis[\"missing\"].remove(question_data[\"target_dimension\"])\n",
        "                if question_data.get(\"target_dimension\") in analysis.get(\"ambiguous\", {}):\n",
        "                    del analysis[\"ambiguous\"][question_data[\"target_dimension\"]]\n",
        "            else:\n",
        "                print(\"Invalid choice, skipping...\")\n",
        "                engine.questions_asked += 1\n",
        "\n",
        "    # Show results\n",
        "    show_results(engine)\n",
        "\n",
        "\n",
        "def run_migration_mode():\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"   RENTSENSE - Migration Mode\")\n",
        "    print(\"   Already in NYC? Let's find somewhere better.\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    engine = QuestionEngineV2(mode=\"migration\")\n",
        "\n",
        "    # Get ZIP\n",
        "    zip_code = input(\"\\nWhat's your current ZIP code? \")\n",
        "    engine.zip_code = zip_code\n",
        "\n",
        "    # Get pros/cons\n",
        "    print(f\"\\nüìç Got it ‚Äî {zip_code}\")\n",
        "    print(\"\\nTell me: What do you love AND what would you change\")\n",
        "    print(\"about your current neighborhood?\\n\")\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Analyze input\n",
        "    print(\"\\nüîç Understanding your experience...\")\n",
        "    analysis = engine.analyze_input(user_input)\n",
        "\n",
        "    # Show what we understood\n",
        "    if analysis.get(\"clear\"):\n",
        "        print(\"\\n‚úì I heard you:\")\n",
        "        for dim, info in analysis[\"clear\"].items():\n",
        "            print(f\"   ‚Ä¢ {dim}: {info.get('evidence', 'mentioned')}\")\n",
        "\n",
        "    # Question loop (fewer for migration)\n",
        "    max_questions = 2\n",
        "\n",
        "    while engine.should_continue(max_questions):\n",
        "        question_data = engine.generate_question(analysis)\n",
        "\n",
        "        if not question_data:\n",
        "            break\n",
        "\n",
        "        # Display question\n",
        "        print(f\"\\n{'‚îÄ' * 50}\")\n",
        "        print(f\"Question {engine.questions_asked + 1}\")\n",
        "        print(f\"{'‚îÄ' * 50}\")\n",
        "        print(f\"\\n{question_data['question']}\\n\")\n",
        "\n",
        "        for opt in question_data[\"options\"]:\n",
        "            print(f\"  {opt['id']}) {opt['label']}\")\n",
        "\n",
        "        if question_data[\"format\"] == \"MCQ_MULTI\":\n",
        "            print(f\"\\n  (Select multiple, comma-separated: A,C)\")\n",
        "\n",
        "        print(f\"\\n  S) Skip\")\n",
        "        print(f\"  X) Show results now\")\n",
        "\n",
        "        # Get answer\n",
        "        answer = input(\"\\nYour choice: \").strip().upper()\n",
        "\n",
        "        if answer == \"X\":\n",
        "            break\n",
        "        elif answer == \"S\":\n",
        "            engine.questions_asked += 1\n",
        "            if question_data.get(\"target_dimension\") in analysis.get(\"missing\", []):\n",
        "                analysis[\"missing\"].remove(question_data[\"target_dimension\"])\n",
        "        else:\n",
        "            selected = [a.strip() for a in answer.split(\",\")]\n",
        "            valid_ids = [opt[\"id\"] for opt in question_data[\"options\"]]\n",
        "            selected = [s for s in selected if s in valid_ids]\n",
        "\n",
        "            if selected:\n",
        "                engine.process_answer(question_data, selected)\n",
        "                if question_data.get(\"target_dimension\") in analysis.get(\"missing\", []):\n",
        "                    analysis[\"missing\"].remove(question_data[\"target_dimension\"])\n",
        "                if question_data.get(\"target_dimension\") in analysis.get(\"ambiguous\", {}):\n",
        "                    del analysis[\"ambiguous\"][question_data[\"target_dimension\"]]\n",
        "            else:\n",
        "                print(\"Invalid choice, skipping...\")\n",
        "                engine.questions_asked += 1\n",
        "\n",
        "    # Show results\n",
        "    show_results(engine)\n",
        "\n",
        "\n",
        "def show_results(engine):\n",
        "    \"\"\"Display final weights.\"\"\"\n",
        "    weights = engine.get_weights()\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(\"YOUR PREFERENCE WEIGHTS (sum to 8)\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    total = 0\n",
        "    for dimension, weight in weights.items():\n",
        "        bar_length = int(weight * 5)\n",
        "        bar = \"‚ñà\" * bar_length + \"‚ñë\" * (10 - bar_length)\n",
        "        print(f\"  {dimension:28s} {weight:.2f}  {bar}\")\n",
        "        total += weight\n",
        "\n",
        "    print(f\"\\n{'‚îÄ' * 60}\")\n",
        "    print(f\"Total: {total:.2f}\")\n",
        "    print(f\"Questions asked: {engine.questions_asked}\")\n",
        "    print(f\"Dimensions covered: {len(engine.dimensions_covered)}/{len(DIMENSIONS)}\")\n",
        "    print(f\"{'‚îÄ' * 60}\")\n",
        "\n",
        "    # Show what we learned\n",
        "    print(f\"\\nüìã Summary:\")\n",
        "    top_3 = list(weights.items())[:3]\n",
        "    print(f\"   Your top priorities: {', '.join([d[0] for d in top_3])}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"   üè† RENTSENSE - Neighborhood Recommendation Engine\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"\\nAre you new to NYC or already living here?\\n\")\n",
        "    print(\"  1) I'm new to NYC (Discovery Mode)\")\n",
        "    print(\"  2) I already live here (Migration Mode)\")\n",
        "\n",
        "    choice = input(\"\\nYour choice (1 or 2): \").strip()\n",
        "\n",
        "    if choice == \"2\":\n",
        "        run_migration_mode()\n",
        "    else:\n",
        "        run_discovery_mode()\n",
        "\n",
        "    print(\"\\n‚úì Done! Next step: Use these weights to score neighborhoods.\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
